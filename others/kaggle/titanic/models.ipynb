{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')  # If the file is in your working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Shorney, Mr. Charles Joseph</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>374910</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Goldschmidt, Mr. George B</td>\n",
       "      <td>male</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17754</td>\n",
       "      <td>34.6542</td>\n",
       "      <td>A5</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Greenfield, Mr. William Bertram</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17759</td>\n",
       "      <td>63.3583</td>\n",
       "      <td>D10 D12</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Doling, Mrs. John T (Ada Julia Bone)</td>\n",
       "      <td>female</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>231919</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Kantor, Mr. Sinai</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>244367</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "0             1         0       3   \n",
       "1             2         1       1   \n",
       "2             3         1       3   \n",
       "3             4         1       1   \n",
       "4             5         0       3   \n",
       "..          ...       ...     ...   \n",
       "95           96         0       3   \n",
       "96           97         0       1   \n",
       "97           98         1       1   \n",
       "98           99         1       2   \n",
       "99          100         0       2   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "0                             Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                              Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                            Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                ...     ...   ...    ...   \n",
       "95                        Shorney, Mr. Charles Joseph    male   NaN      0   \n",
       "96                          Goldschmidt, Mr. George B    male  71.0      0   \n",
       "97                    Greenfield, Mr. William Bertram    male  23.0      0   \n",
       "98               Doling, Mrs. John T (Ada Julia Bone)  female  34.0      0   \n",
       "99                                  Kantor, Mr. Sinai    male  34.0      1   \n",
       "\n",
       "    Parch            Ticket     Fare    Cabin Embarked  \n",
       "0       0         A/5 21171   7.2500      NaN        S  \n",
       "1       0          PC 17599  71.2833      C85        C  \n",
       "2       0  STON/O2. 3101282   7.9250      NaN        S  \n",
       "3       0            113803  53.1000     C123        S  \n",
       "4       0            373450   8.0500      NaN        S  \n",
       "..    ...               ...      ...      ...      ...  \n",
       "95      0            374910   8.0500      NaN        S  \n",
       "96      0          PC 17754  34.6542       A5        C  \n",
       "97      1          PC 17759  63.3583  D10 D12        C  \n",
       "98      1            231919  23.0000      NaN        S  \n",
       "99      0            244367  26.0000      NaN        S  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\zzjas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seaborn) (1.26.1)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\zzjas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\zzjas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seaborn) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\zzjas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\zzjas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\zzjas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\zzjas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\zzjas\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\zzjas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\zzjas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\zzjas\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\zzjas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\zzjas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\zzjas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\zzjas\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zzjas\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!pip install scikit-learn, !pip install xgboost\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data): # transform text to number for machine leaarning\n",
    "    data['Fare'] = data['Fare'].fillna(data['Fare'].dropna().median())\n",
    "    data['Age'] = data['Age'].fillna(data['Age'].dropna().median())\n",
    "    \n",
    "    data.loc[data['Sex'] == 'male', 'Sex'] = 0\n",
    "    data.loc[data['Sex'] == 'female', 'Sex'] = 1\n",
    "    \n",
    "    data['Embarked'] = data['Embarked'].fillna('S') # if no data, fill with S\n",
    "    data.loc[data['Embarked'] == 'S', 'Embarked'] = 0\n",
    "    data.loc[data['Embarked'] == 'C', 'Embarked'] = 1\n",
    "    data.loc[data['Embarked'] == 'Q', 'Embarked'] = 2\n",
    "    \n",
    "# clean data\n",
    "clean_data(train_data)\n",
    "clean_data(test_data)\n",
    "\n",
    "# label\n",
    "y = train_data[\"Survived\"]\n",
    "# features choose 5\n",
    "features = train_data[['Pclass', 'Age', 'Sex', 'SibSp', 'Parch', \"Fare\", \"Embarked\"]].values\n",
    "test_features = test_data[['Pclass', 'Age', 'Sex', 'SibSp', 'Parch', \"Fare\", \"Embarked\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1 0.6161616161616161\n",
      "1 1 3 0.621773288439955\n",
      "1 3 1 0.8035914702581369\n",
      "1 3 3 0.8002244668911336\n",
      "1 5 1 0.8047138047138047\n",
      "1 5 3 0.8383838383838383\n",
      "1 7 1 0.8451178451178452\n",
      "1 7 3 0.8372615039281706\n",
      "1 9 1 0.8395061728395061\n",
      "1 9 3 0.877665544332211\n",
      "11 1 1 0.7676767676767676\n",
      "11 1 3 0.6453423120089786\n",
      "11 3 1 0.8148148148148148\n",
      "11 3 3 0.8204264870931538\n",
      "11 5 1 0.8529741863075196\n",
      "11 5 3 0.8518518518518519\n",
      "11 7 1 0.8765432098765432\n",
      "11 7 3 0.8799102132435466\n",
      "11 9 1 0.9147025813692481\n",
      "11 9 3 0.920314253647587\n",
      "21 1 1 0.7833894500561167\n",
      "21 1 3 0.77665544332211\n",
      "21 3 1 0.8047138047138047\n",
      "21 3 3 0.8361391694725028\n",
      "21 5 1 0.8518518518518519\n",
      "21 5 3 0.8518518518518519\n",
      "21 7 1 0.8787878787878788\n",
      "21 7 3 0.8866442199775533\n",
      "21 9 1 0.9147025813692481\n",
      "21 9 3 0.9180695847362514\n",
      "31 1 1 0.7856341189674523\n",
      "31 1 3 0.77665544332211\n",
      "31 3 1 0.8047138047138047\n",
      "31 3 3 0.8316498316498316\n",
      "31 5 1 0.8529741863075196\n",
      "31 5 3 0.8518518518518519\n",
      "31 7 1 0.8832772166105499\n",
      "31 7 3 0.8832772166105499\n",
      "31 9 1 0.9236812570145904\n",
      "31 9 3 0.9236812570145904\n",
      "41 1 1 0.7508417508417509\n",
      "41 1 3 0.7755331088664422\n",
      "41 3 1 0.813692480359147\n",
      "41 3 3 0.835016835016835\n",
      "41 5 1 0.8529741863075196\n",
      "41 5 3 0.8507295173961841\n",
      "41 7 1 0.8843995510662177\n",
      "41 7 3 0.8855218855218855\n",
      "41 9 1 0.9270482603815937\n",
      "41 9 3 0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "def parameterTesting():\n",
    "    for n_estimators in range(1, 51, 10):\n",
    "        for max_depth in range(1, 10, 2):\n",
    "            for random_state in range(1, 5, 2):\n",
    "                model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n",
    "                model.fit(features, y)\n",
    "                predictions = model.predict(test_features)\n",
    "\n",
    "                # output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "                # output.to_csv('my_submission.csv', index=False)\n",
    "                # print(\"Your submission was successfully saved!\")\n",
    "                print(n_estimators, max_depth, random_state, model.score(features, y))\n",
    "parameterTesting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n",
      "0.8877665544332211\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=50, max_depth=7, random_state=1)\n",
    "model.fit(features, y)\n",
    "predictions = model.predict(test_features)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")\n",
    "print(model.score(features, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data): # transform text to number for machine leaarning\n",
    "    data['Fare'].fillna(data['Fare'].median(), inplace=True)\n",
    "    data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "    data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
    "    data['Embarked'] = data['Embarked'].fillna('S') # if no data, fill with S\n",
    "    data['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "    \n",
    "    \n",
    "# clean data\n",
    "clean_data(train_data)\n",
    "clean_data(test_data)\n",
    "\n",
    "# label\n",
    "y = train_data[\"Survived\"]\n",
    "# features choose 5\n",
    "features = train_data[['Pclass', 'Age', 'Sex', 'SibSp', 'Parch', \"Fare\", \"Embarked\"]].values\n",
    "test_features = test_data[['Pclass', 'Age', 'Sex', 'SibSp', 'Parch', \"Fare\", \"Embarked\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n",
      "0.856341189674523\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(n_estimators=200, max_depth=5, learning_rate=0.08, random_state=42)\n",
    "model.fit(features, y)\n",
    "predictions = model.predict(test_features)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")\n",
    "print(model.score(features, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter search...\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zzjas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:30:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\zzjas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:30:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on CV: 0.8507145346810736\n",
      "Best params: {'subsample': 0.6, 'n_estimators': 200, 'min_child_weight': 2, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 0.9}\n",
      "Validation Accuracy: 0.7836, AUC: 0.8045\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Titanic XGBoost notebook-style script\n",
    "# Feature engineering + XGBoost + RandomizedSearchCV hyperparameter tuning\n",
    "# Expected to reach ~0.80+ with solid feature engineering\n",
    "\n",
    "# Requirements:\n",
    "# pip install pandas numpy scikit-learn xgboost matplotlib seaborn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# import joblib\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Load data\n",
    "# ---------------------------\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "full = pd.concat([train, test], sort=False).reset_index(drop=True)\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Feature engineering\n",
    "# ---------------------------\n",
    "# 2.1 Title from Name\n",
    "full['Title'] = full['Name'].str.extract(r',\\s*([^\\.]+)\\.', expand=False)\n",
    "# Group rare titles\n",
    "title_map = {\n",
    "    'Mr': 'Mr', 'Mrs': 'Mrs', 'Miss': 'Miss', 'Master': 'Master'\n",
    "}\n",
    "full['Title'] = full['Title'].map(lambda x: title_map.get(x.strip(), 'Rare') if isinstance(x, str) else 'Rare')\n",
    "\n",
    "# 2.2 Family features\n",
    "full['FamilySize'] = full['SibSp'] + full['Parch'] + 1\n",
    "full['IsAlone'] = (full['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# 2.3 Fill Embarked and Fare missing\n",
    "full['Embarked'] = full['Embarked'].fillna(full['Embarked'].mode()[0])\n",
    "full['Fare'] = full['Fare'].fillna(full['Fare'].median())\n",
    "\n",
    "# 2.4 Age imputation using median by Title + Pclass\n",
    "# Compute median ages for grouping\n",
    "age_med = full.groupby(['Title', 'Pclass'])['Age'].median()\n",
    "\n",
    "def impute_age(row):\n",
    "    if pd.isna(row['Age']):\n",
    "        med = age_med.get((row['Title'], row['Pclass']))\n",
    "        if np.isnan(med):\n",
    "            return full['Age'].median()\n",
    "        return med\n",
    "    return row['Age']\n",
    "\n",
    "full['Age'] = full.apply(impute_age, axis=1)\n",
    "\n",
    "# 2.5 Create Age bands and Fare bands\n",
    "full['AgeBand'] = pd.cut(full['Age'], bins=[0,12,20,40,60,99], labels=[0,1,2,3,4]).astype(int)\n",
    "full['FareBand'] = pd.qcut(full['Fare'], 4, labels=False)\n",
    "\n",
    "# 2.6 Cabin: has cabin or not\n",
    "full['HasCabin'] = full['Cabin'].notnull().astype(int)\n",
    "\n",
    "# 2.7 Ticket: create ticket prefix\n",
    "full['TicketPrefix'] = full['Ticket'].str.replace('[\\.\\/]','',regex=True).str.split().str[0]\n",
    "full['TicketPrefix'] = full['TicketPrefix'].apply(lambda x: x if x.isalpha() else 'NONE')\n",
    "\n",
    "# 2.8 Drop/transform columns we won't use raw\n",
    "# Keep PassengerId for submission\n",
    "# Define features to use later\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Encoding categorical variables\n",
    "# ---------------------------\n",
    "# We'll label encode some ordinal-like features, and one-hot encode others via pandas.get_dummies.\n",
    "categorical = ['Sex', 'Embarked', 'Title', 'TicketPrefix', 'HasCabin']\n",
    "\n",
    "# Label encode Sex\n",
    "full['Sex'] = full['Sex'].map({'male':0, 'female':1}).astype(int)\n",
    "\n",
    "# One-hot for selected categorical features using get_dummies (drops first to avoid collinearity)\n",
    "full = pd.get_dummies(full, columns=['Embarked','Title','TicketPrefix'], drop_first=True)\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Split back to train/test and prepare X/y\n",
    "# ---------------------------\n",
    "train_processed = full[full['Survived'].notnull()].copy()\n",
    "test_processed = full[full['Survived'].isnull()].copy()\n",
    "\n",
    "FEATURES = [\n",
    "    'Pclass','Sex','Age','SibSp','Parch','Fare','FamilySize','IsAlone',\n",
    "    'AgeBand','FareBand','HasCabin'\n",
    "]\n",
    "# add dynamic dummies\n",
    "dummies = [c for c in train_processed.columns if c.startswith('Embarked_') or c.startswith('Title_') or c.startswith('TicketPrefix_')]\n",
    "FEATURES += dummies\n",
    "\n",
    "X = train_processed[FEATURES]\n",
    "y = train_processed['Survived'].astype(int)\n",
    "X_test = test_processed[FEATURES]\n",
    "\n",
    "# Quick check for any remaining NaNs\n",
    "assert X.isnull().sum().sum() == 0, 'Nulls in training features'\n",
    "assert X_test.isnull().sum().sum() == 0, 'Nulls in test features'\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Train/validation split\n",
    "# ---------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, stratify=y, random_state=RANDOM_STATE)\n",
    "\n",
    "# ---------------------------\n",
    "# 6) XGBoost with RandomizedSearchCV\n",
    "# ---------------------------\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [3, 4, 5, 6, 8],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'min_child_weight': [1, 2, 3, 5]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=40,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=cv,\n",
    "    verbose=2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print('Starting hyperparameter search...')\n",
    "rs.fit(X_train, y_train)\n",
    "\n",
    "print('Best score on CV:', rs.best_score_)\n",
    "print('Best params:', rs.best_params_)\n",
    "\n",
    "# Evaluate on validation set\n",
    "best_model = rs.best_estimator_\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "val_acc = accuracy_score(y_val, y_val_pred)\n",
    "val_auc = roc_auc_score(y_val, best_model.predict_proba(X_val)[:,1])\n",
    "print(f'Validation Accuracy: {val_acc:.4f}, AUC: {val_auc:.4f}')\n",
    "\n",
    "# ---------------------------\n",
    "# 7) Fit on full training data with best params and predict test\n",
    "# ---------------------------\n",
    "best_model_full = XGBClassifier(**rs.best_params_, use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE)\n",
    "best_model_full.fit(X, y)\n",
    "\n",
    "preds_test = best_model_full.predict(X_test).astype(int)\n",
    "\n",
    "# ---------------------------\n",
    "# 8) Save submission\n",
    "# ---------------------------\n",
    "# submission = pd.DataFrame({'PassengerId': test_processed['PassengerId'].astype(int), 'Survived': preds_test})\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "# print('Saved submission.csv')\n",
    "\n",
    "# # Save model\n",
    "# joblib.dump(best_model_full, 'xgb_titanic_best.pkl')\n",
    "# print('Saved model to xgb_titanic_best.pkl')\n",
    "\n",
    "# ---------------------------\n",
    "# 9) Optional: Feature importance plot\n",
    "# ---------------------------\n",
    "# fi = pd.Series(best_model_full.feature_importances_, index=FEATURES).sort_values(ascending=False)\n",
    "# plt.figure(figsize=(10,6))\n",
    "# fi.head(20).plot(kind='barh')\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.title('Top feature importances')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('feature_importance.png')\n",
    "# print('Saved feature_importance.png')\n",
    "\n",
    "# ---------------------------\n",
    "# 10) Notes & next steps\n",
    "# ---------------------------\n",
    "# - You can improve results further by:\n",
    "#   * More sophisticated age imputation (e.g., model-based)\n",
    "#   * Creating interaction features (e.g., Title*Pclass, FarePerPerson)\n",
    "#   * Using stacking/blending of models (LightGBM, CatBoost)\n",
    "#   * Targeted hyperparameter tuning with more iterations or Bayesian optimization (Optuna)\n",
    "# - For reproducibility, ensure versions of libraries are pinned (xgboost, scikit-learn, pandas)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission.csv\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({'PassengerId': test_processed['PassengerId'].astype(int), 'Survived': preds_test})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('Saved submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
